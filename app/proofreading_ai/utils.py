import re
import html
import difflib
from typing import Dict, List, Tuple, Union


def get_html_diff(original: str, corrected: str) -> str:
    """
    åŸæ–‡ã¨æ ¡æ­£æ–‡ã®å·®åˆ†ã‚’HTMLå½¢å¼ã§è¿”ã™
    
    Args:
        original: åŸæ–‡
        corrected: æ ¡æ­£æ–‡
        
    Returns:
        å·®åˆ†ã‚’è¡¨ç¤ºã™ã‚‹HTML
    """
    # HTMLã‚¿ã‚°ã®ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ï¼ˆå®Ÿéš›ã®è¡¨ç¤ºç”¨ï¼‰
    escaped_original = html.escape(original)
    escaped_corrected = html.escape(corrected)
    
    # å·®åˆ†ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ç”Ÿæˆ
    differ = difflib.Differ()
    diff = list(differ.compare(escaped_original.splitlines(), escaped_corrected.splitlines()))
    
    # HTMLç”Ÿæˆ
    html_diff = []
    for line in diff:
        if line.startswith('+ '):
            # è¿½åŠ è¡Œ
            html_diff.append(f'<div class="diff-added">{line[2:]}</div>')
        elif line.startswith('- '):
            # å‰Šé™¤è¡Œ
            html_diff.append(f'<div class="diff-removed">{line[2:]}</div>')
        elif line.startswith('? '):
            # å¤‰æ›´ç®‡æ‰€ã®ãƒãƒ¼ã‚«ãƒ¼ï¼ˆè¡¨ç¤ºã—ãªã„ï¼‰
            continue
        else:
            # å¤‰æ›´ãªã—
            html_diff.append(f'<div class="diff-unchanged">{line[2:]}</div>')
    
    return ''.join(html_diff)


def load_replacement_dict(replacements: List[Dict[str, str]]) -> Dict[str, str]:
    """
    ç½®æ›è¾æ›¸ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹
    
    Args:
        replacements: DBã‹ã‚‰å–å¾—ã—ãŸç½®æ›è¾æ›¸ã‚¨ãƒ³ãƒˆãƒªã®ãƒªã‚¹ãƒˆ
        
    Returns:
        {å…ƒã®èªå¥: ç½®æ›å¾Œã®èªå¥} ã®å½¢å¼ã®è¾æ›¸
    """
    return {item['original_word']: item['replacement_word'] for item in replacements if item.get('is_active', True)}


def protect_html_tags(text: str) -> Tuple[str, Dict[str, str]]:
    """
    HTMLã‚¿ã‚°ã‚’ä¸€æ™‚çš„ã«ç½®æ›ã—ã¦AIå‡¦ç†ã‹ã‚‰ä¿è­·ã™ã‚‹
    
    Args:
        text: å…ƒãƒ†ã‚­ã‚¹ãƒˆ
        
    Returns:
        ã‚¿ã‚°ã‚’ç½®æ›ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°è¾æ›¸
    """
    # HTMLã‚¿ã‚°ã‚’æ¤œå‡ºã™ã‚‹æ­£è¦è¡¨ç¾ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¿ã‚°ã‚‚å«ã‚€ï¼‰
    tag_pattern = r'(<[^>]+>|<!--[\s\S]*?-->)'
    tags = re.findall(tag_pattern, text)
    
    # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã¨ã‚¿ã‚°ã®ãƒãƒƒãƒ”ãƒ³ã‚°è¾æ›¸
    placeholders = {}
    protected_text = text
    
    # å„ã‚¿ã‚°ã‚’ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã«ç½®æ›
    for i, tag in enumerate(tags):
        placeholder = f"__HTML_TAG_{i}__"
        # ä¸€åº¦ã«1ã¤ã ã‘ç½®æ›ã—ã¦ã€åŒã˜ã‚¿ã‚°ãŒè¤‡æ•°ã‚ã‚‹å ´åˆã§ã‚‚åŒºåˆ¥ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
        protected_text = protected_text.replace(tag, placeholder, 1)
        placeholders[placeholder] = tag
    
    return protected_text, placeholders


def restore_html_tags(text: str, placeholders: Dict[str, str]) -> str:
    """
    ä¿è­·ã—ãŸHTMLã‚¿ã‚°ã‚’å…ƒã«æˆ»ã™
    
    Args:
        text: ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆ
        placeholders: ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã¨ã‚¿ã‚°ã®ãƒãƒƒãƒ”ãƒ³ã‚°è¾æ›¸
        
    Returns:
        ã‚¿ã‚°ã‚’å¾©å…ƒã—ãŸãƒ†ã‚­ã‚¹ãƒˆ
    """
    # é•·ã„ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‹ã‚‰çŸ­ã„ã‚‚ã®ã¸ã¨å‡¦ç†ã™ã‚‹ã¨ã‚¨ãƒ©ãƒ¼ãŒå°‘ãªã„
    sorted_placeholders = sorted(placeholders.items(), key=lambda x: len(x[0]), reverse=True)
    
    result = text
    for placeholder, tag in sorted_placeholders:
        # ã™ã¹ã¦ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’å¯¾å¿œã™ã‚‹ã‚¿ã‚°ã«ç½®æ›
        result = result.replace(placeholder, tag)
    
    return result 


def format_corrections(original_text: str, corrections: List[Dict]) -> str:
    """
    æ ¡æ­£çµæœã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆä»˜ãHTMLã¨ã—ã¦ç”Ÿæˆã™ã‚‹ï¼ˆ4è‰²ã‚«ãƒ†ã‚´ãƒªãƒ¼å¯¾å¿œãƒ»æ”¹è‰¯ç‰ˆï¼‰
    original_text: å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆHTMLã‚¿ã‚°å«ã‚€ï¼‰
    corrections: [{'original': 'xxx', 'corrected': 'yyy', 'reason': '...', 'category': 'tone|typo|dict|inconsistency'}]
    """
    if not corrections:
        # ä¿®æ­£ç®‡æ‰€ãŒãªã„å ´åˆã¯å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã—ã¦è¿”ã™
        return html.escape(original_text)
    
    result = []
    last_idx = 0
    used_positions = set()  # ä½¿ç”¨æ¸ˆã¿ä½ç½®ã‚’è¨˜éŒ²
    
    # ä¿®æ­£ç®‡æ‰€ã‚’ä½ç½®é †ã«ã‚½ãƒ¼ãƒˆ
    sorted_corrections = []
    for corr in corrections:
        original_word = corr.get("original", "")
        if original_word:
            # è¤‡æ•°ã®å‡ºç¾ä½ç½®ã‚’æ¤œç´¢
            start = 0
            while True:
                pos = original_text.find(original_word, start)
                if pos == -1:
                    break
                # æ—¢ã«ä½¿ç”¨æ¸ˆã¿ã§ãªã„ä½ç½®ã®ã¿è¿½åŠ 
                if pos not in used_positions:
                    sorted_corrections.append((pos, corr))
                    break
                start = pos + 1
    
    # ä½ç½®é †ã«ã‚½ãƒ¼ãƒˆ
    sorted_corrections.sort(key=lambda x: x[0])
    
    for start_pos, corr in sorted_corrections:
        # æ—¢ã«å‡¦ç†æ¸ˆã¿ã®ä½ç½®ã¯ã‚¹ã‚­ãƒƒãƒ—
        if start_pos in used_positions:
            continue
            
        # ç¾åœ¨ã®ä½ç½®ã‚ˆã‚Šå‰ã®ä½ç½®ã¯ã‚¹ã‚­ãƒƒãƒ—
        if start_pos < last_idx:
            continue
            
        original_word = corr.get("original", "")
        corrected_word = corr.get("corrected", "")
        reason = corr.get("reason", "")
        category = corr.get("category", "general")
        
        end_pos = start_pos + len(original_word)
        
        # ä¿®æ­£å‰ã®éƒ¨åˆ†
        result.append(html.escape(original_text[last_idx:start_pos]))
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«å¿œã˜ãŸCSSã‚¯ãƒ©ã‚¹ã‚’æ±ºå®š
        css_class = f"correction-{category}" if category in ["tone", "typo", "dict", "inconsistency"] else "correction-text"
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼åã¨ã‚¢ã‚¤ã‚³ãƒ³ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        category_info = {
            'typo': {'name': 'èª¤å­—ä¿®æ­£', 'icon': 'ğŸ”¤', 'color': '#dc2626'},
            'tone': {'name': 'è¨€ã„å›ã—æ”¹å–„', 'icon': 'âœ¨', 'color': '#7c3aed'},
            'dict': {'name': 'è¾æ›¸ãƒ«ãƒ¼ãƒ«', 'icon': 'ğŸ“š', 'color': '#d97706'},
            'inconsistency': {'name': 'çŸ›ç›¾ãƒã‚§ãƒƒã‚¯', 'icon': 'âš ï¸', 'color': '#c2410c'}
        }
        
        cat_info = category_info.get(category, {'name': 'ä¿®æ­£', 'icon': 'ğŸ“', 'color': '#6b7280'})
        
        # ä¿®æ­£ç®‡æ‰€ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆï¼ˆ4è‰²ã‚«ãƒ†ã‚´ãƒªãƒ¼å¯¾å¿œãƒ»ä¿®æ­£å‰æ–‡å­—åˆ—è¡¨ç¤ºã«å¤‰æ›´ï¼‰
        result.append(
            f'<span class="correction-span" '
            f'data-original="{html.escape(original_word)}" '
            f'data-corrected="{html.escape(corrected_word)}" '
            f'data-reason="{html.escape(reason)}" '
            f'data-category="{category}">'
            f'<span class="{css_class}">{html.escape(original_word)}</span>'
            f'<span class="correction-tooltip">'
            f'<div class="tooltip-category-badge" style="background: {cat_info["color"]}; color: white; padding: 4px 8px; border-radius: 12px; font-size: 11px; font-weight: 600; margin-bottom: 8px; text-align: center;">'
            f'{cat_info["icon"]} {cat_info["name"]}'
            f'</div>'
            f'<div class="tooltip-original clickable-correction" data-action="revert" title="ã‚¯ãƒªãƒƒã‚¯ã—ã¦å…ƒã«æˆ»ã™">{html.escape(original_word)}</div>'
            f'<div class="tooltip-corrected clickable-correction" data-action="apply" title="ã‚¯ãƒªãƒƒã‚¯ã—ã¦ä¿®æ­£ã‚’é©ç”¨">{html.escape(corrected_word)}</div>'
            f'<div class="tooltip-reason">{html.escape(reason)}</div>'
            f'</span>'
            f'</span>'
        )
        
        # ä½¿ç”¨æ¸ˆã¿ä½ç½®ã‚’è¨˜éŒ²
        for i in range(start_pos, end_pos):
            used_positions.add(i)
            
        last_idx = end_pos
    
    # æ®‹ã‚Šã®éƒ¨åˆ†
    result.append(html.escape(original_text[last_idx:]))
    
    return ''.join(result)


def parse_corrections_from_text(corrected_text: str) -> List[Dict[str, str]]:
    """
    Claude Sonnet 4ã®æ ¡æ­£APIè¿”å´å€¤ã‹ã‚‰ä¿®æ­£ç®‡æ‰€ãƒªã‚¹ãƒˆã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹ï¼ˆ4è‰²ã‚«ãƒ†ã‚´ãƒªãƒ¼å¯¾å¿œï¼‰
    - ã‚«ãƒ†ã‚´ãƒªãƒ¼: tone | (å¤‰æ›´å‰) -> (å¤‰æ›´å¾Œ): ç†ç”±
    ã®å½¢å¼ã‚’æŠ½å‡ºã—ã€original, corrected, reason, categoryã®dictãƒªã‚¹ãƒˆã§è¿”ã™
    """
    corrections = []
    seen_corrections = set()  # é‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨
    
    # ã€Œâœ…ä¿®æ­£ç®‡æ‰€ï¼šã€ä»¥é™ã‚’æŠ½å‡º
    if "âœ…ä¿®æ­£ç®‡æ‰€ï¼š" not in corrected_text:
        return corrections
    try:
        _, after = corrected_text.split("âœ…ä¿®æ­£ç®‡æ‰€ï¼š", 1)
    except ValueError:
        return corrections
    
    # å„è¡Œã‚’ãƒ‘ãƒ¼ã‚¹
    for line in after.splitlines():
        line = line.strip()
        if not line or not line.startswith("-"):
            continue
        
        # Claude Sonnet 4ã®æ–°å½¢å¼: - ã‚«ãƒ†ã‚´ãƒªãƒ¼: tone | (å¤‰æ›´å‰) -> (å¤‰æ›´å¾Œ): ç†ç”±
        category_match = re.match(r"- ã‚«ãƒ†ã‚´ãƒªãƒ¼: (tone|typo|dict|inconsistency) \| \((.*?)\) -> \((.*?)\): ?(.*)", line)
        if category_match:
            category, original, corrected, reason = category_match.groups()
            original = original.strip()
            corrected = corrected.strip()
            reason = reason.strip()
            
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆåŒã˜ original -> corrected ã®çµ„ã¿åˆã‚ã›ã¯é™¤å¤–ï¼‰
            correction_key = (original, corrected)
            if correction_key not in seen_corrections:
                seen_corrections.add(correction_key)
                corrections.append({
                    "original": original,
                    "corrected": corrected,
                    "reason": reason,
                    "category": category,
                })
            continue
        
        # å¾“æ¥å½¢å¼ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰: - è¡Œç•ªå·: (å¤‰æ›´å‰) -> (å¤‰æ›´å¾Œ): ç†ç”±
        legacy_match = re.match(r"- [^:]+: \((.*?)\) -> \((.*?)\): ?(.*)", line)
        if legacy_match:
            original, corrected, reason = legacy_match.groups()
            original = original.strip()
            corrected = corrected.strip()
            reason = reason.strip()
            
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆåŒã˜ original -> corrected ã®çµ„ã¿åˆã‚ã›ã¯é™¤å¤–ï¼‰
            correction_key = (original, corrected)
            if correction_key not in seen_corrections:
                seen_corrections.add(correction_key)
                corrections.append({
                    "original": original,
                    "corrected": corrected,
                    "reason": reason,
                    "category": "general",  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚«ãƒ†ã‚´ãƒªãƒ¼
                })
    
    return corrections 


def protect_html_tags_advanced(text: str) -> Tuple[str, Dict[str, str], List[Dict]]:
    """
    HTMLã‚¿ã‚°ã‚’è©³ç´°è§£æã—ã¦ã€ã‚¿ã‚°å†…ã®èª¤å­—ã‚‚æ¤œå‡ºã§ãã‚‹ã‚ˆã†ã«æ”¹å–„ã•ã‚ŒãŸä¿è­·æ©Ÿèƒ½
    
    Args:
        text: å…ƒãƒ†ã‚­ã‚¹ãƒˆ
        
    Returns:
        ã‚¿ã‚°ã‚’ç½®æ›ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã€ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°è¾æ›¸ã€HTMLã‚¿ã‚°æƒ…å ±ãƒªã‚¹ãƒˆ
    """
    # HTMLã‚¿ã‚°ã‚’æ¤œå‡ºã™ã‚‹æ­£è¦è¡¨ç¾ï¼ˆé–‹å§‹ã‚¿ã‚°ã€çµ‚äº†ã‚¿ã‚°ã€ã‚³ãƒ¡ãƒ³ãƒˆã‚¿ã‚°ï¼‰
    tag_pattern = r'(<(/?)([a-zA-Z][a-zA-Z0-9]*)\s*([^>]*?)>|<!--[\s\S]*?-->)'
    
    placeholders = {}
    html_tag_info = []
    protected_text = text
    tag_counter = 0
    
    def replace_tag(match):
        nonlocal tag_counter, placeholders, html_tag_info
        
        full_tag = match.group(0)
        
        # ã‚³ãƒ¡ãƒ³ãƒˆã‚¿ã‚°ã®å ´åˆã¯å¾“æ¥é€šã‚Šä¿è­·
        if full_tag.startswith('<!--'):
            placeholder = f"__HTML_TAG_{tag_counter}__"
            placeholders[placeholder] = full_tag
            tag_counter += 1
            return placeholder
        
        # é€šå¸¸ã®HTMLã‚¿ã‚°ã®è§£æ
        is_closing = bool(match.group(2))  # "/" ãŒã‚ã‚‹ã‹ã©ã†ã‹
        tag_name = match.group(3)
        attributes = match.group(4).strip() if match.group(4) else ""
        
        if is_closing:
            # çµ‚äº†ã‚¿ã‚°ã¯ä¿è­·ï¼ˆæ ¡æ­£å¯¾è±¡å¤–ï¼‰
            placeholder = f"__HTML_TAG_{tag_counter}__"
            placeholders[placeholder] = full_tag
            tag_counter += 1
            return placeholder
        else:
            # é–‹å§‹ã‚¿ã‚°ã®å ´åˆã€å±æ€§éƒ¨åˆ†ã‚‚æ ¡æ­£å¯¾è±¡ã«ã™ã‚‹
            if attributes:
                # å±æ€§ã‚’æ ¡æ­£å¯èƒ½ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å‡¦ç†
                attr_placeholder = f"__HTML_ATTR_{tag_counter}__"
                
                # HTMLã‚¿ã‚°æƒ…å ±ã‚’ä¿å­˜ï¼ˆtag_counterã‚‚å«ã‚ã‚‹ï¼‰
                html_tag_info.append({
                    'tag_name': tag_name,
                    'attributes_original': attributes,
                    'attr_placeholder': attr_placeholder,
                    'full_placeholder': f"__HTML_TAG_{tag_counter}__",
                    'tag_counter': tag_counter
                })
                
                # ã‚¿ã‚°ã®éª¨æ ¼éƒ¨åˆ†ã®ã¿ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã§ä¿è­·
                tag_skeleton = f"<{tag_name} {attr_placeholder}>"
                placeholder = f"__HTML_TAG_{tag_counter}__"
                placeholders[placeholder] = tag_skeleton
                tag_counter += 1
                
                # å±æ€§éƒ¨åˆ†ã‚’æ ¡æ­£å¯èƒ½ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦æ®‹ã™
                return f"{placeholder} {attributes} __ATTR_END_{tag_counter-1}__"
            else:
                # å±æ€§ãªã—ã®å ´åˆã¯å¾“æ¥é€šã‚Šä¿è­·
                placeholder = f"__HTML_TAG_{tag_counter}__"
                placeholders[placeholder] = full_tag
                tag_counter += 1
                return placeholder
    
    # ã‚¿ã‚°ã‚’ç½®æ›
    protected_text = re.sub(tag_pattern, replace_tag, protected_text)
    
    return protected_text, placeholders, html_tag_info


def restore_html_tags_advanced(text: str, placeholders: Dict[str, str], html_tag_info: List[Dict], corrections: List[Dict]) -> str:
    """
    æ”¹å–„ã•ã‚ŒãŸHTMLã‚¿ã‚°å¾©å…ƒæ©Ÿèƒ½ï¼ˆå±æ€§å†…ã®ä¿®æ­£ã‚‚åæ˜ ï¼‰
    
    Args:
        text: ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆ
        placeholders: ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã¨ã‚¿ã‚°ã®ãƒãƒƒãƒ”ãƒ³ã‚°è¾æ›¸
        html_tag_info: HTMLã‚¿ã‚°è©³ç´°æƒ…å ±
        corrections: ä¿®æ­£ç®‡æ‰€ãƒªã‚¹ãƒˆ
        
    Returns:
        ã‚¿ã‚°ã¨ä¿®æ­£ã‚’å¾©å…ƒã—ãŸãƒ†ã‚­ã‚¹ãƒˆ
    """
    result = text
    
    # å±æ€§å†…ã®ä¿®æ­£ã‚’é©ç”¨
    for i, tag_info in enumerate(html_tag_info):
        attr_placeholder = tag_info['attr_placeholder']
        original_attrs = tag_info['attributes_original']
        tag_name = tag_info['tag_name']
        full_placeholder = tag_info['full_placeholder']
        tag_counter = tag_info['tag_counter']
        attr_end_marker = f"__ATTR_END_{tag_counter}__"
        
        # å±æ€§éƒ¨åˆ†ã«å¯¾ã™ã‚‹ä¿®æ­£ã‚’é©ç”¨
        corrected_attrs = original_attrs
        for correction in corrections:
            if correction['original'] in original_attrs:
                corrected_attrs = corrected_attrs.replace(
                    correction['original'], 
                    correction['corrected']
                )
        
        # ã‚¿ã‚°åã«å¯¾ã™ã‚‹ä¿®æ­£ã‚’é©ç”¨
        corrected_tag_name = tag_name
        for correction in corrections:
            if correction['original'] == tag_name:
                corrected_tag_name = correction['corrected']
        
        # ä¿®æ­£ã•ã‚ŒãŸå®Œå…¨ãªã‚¿ã‚°ã‚’æ§‹ç¯‰
        corrected_tag = f"<{corrected_tag_name} {corrected_attrs}>"
        
        # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’æ›´æ–°
        placeholders[full_placeholder] = corrected_tag
        
        # å±æ€§éƒ¨åˆ†ã¨ã‚¨ãƒ³ãƒ‰ãƒãƒ¼ã‚«ãƒ¼ã‚’é™¤å»
        pattern = f"{re.escape(full_placeholder)} {re.escape(original_attrs)} {re.escape(attr_end_marker)}"
        result = re.sub(pattern, full_placeholder, result)
        
        # çµ‚äº†ã‚¿ã‚°ã‚‚æ›´æ–°ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
        closing_tag_placeholder = f"__HTML_TAG_{tag_counter + 1}__"
        if closing_tag_placeholder in placeholders:
            corrected_closing_tag = f"</{corrected_tag_name}>"
            placeholders[closing_tag_placeholder] = corrected_closing_tag
    
    # æœ¬æ–‡ãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã™ã‚‹ä¿®æ­£ã‚’é©ç”¨
    for correction in corrections:
        original = correction['original']
        corrected = correction['corrected']
        
        # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ä»¥å¤–ã®é€šå¸¸ãƒ†ã‚­ã‚¹ãƒˆéƒ¨åˆ†ã§ä¿®æ­£ã‚’é©ç”¨
        if original in result and not original.startswith('__') and not original.endswith('__'):
            result = result.replace(original, corrected)
    
    # é€šå¸¸ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼å¾©å…ƒ
    sorted_placeholders = sorted(placeholders.items(), key=lambda x: len(x[0]), reverse=True)
    
    for placeholder, tag in sorted_placeholders:
        result = result.replace(placeholder, tag)
    
    return result 